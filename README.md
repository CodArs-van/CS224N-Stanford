# CS224N (2018 Winter)

This repo is used to record my notebooks & homeworks of the well known NLP course from Stanford University.

Official Course Link: http://web.stanford.edu/class/cs224n/


## Topics

### Course Videos

- [x] Lecture 1
- [x] Lecture 2
- [x] Lecture 3

### Course Decks Review

cs224n-2019-lecture[.*]-wordvecs2.pdf

- [ ] Lecture 1
- [ ] Lecture 2

### Course Notes Review

cs224n-2019-notes[.*]-wordvecs1.pdf

- [ ] Lecture 1
- [ ] Lecture 2

### Assignments

- [x] Assignment 1

### Introduction and Word Vectors

Suggested Readings:
- [x] [Singular Value Decomposition Tutorial](https://davetang.org/file/Singular_Value_Decomposition_Tutorial.pdf)
- [x] [Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
- [x] [Efficient Estimation of Word Representations in Vector Space](http://arxiv.org/pdf/1301.3781.pdf) (original word2vec paper)
- [ ] [Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) (negative sampling paper)
- [x] [GloVe: Global Vectors for Word Representation](http://nlp.stanford.edu/pubs/glove.pdf) (original GloVe paper)
- [ ] [Improving Distributional Similarity with Lessons Learned from Word Embeddings](http://www.aclweb.org/anthology/Q15-1016)
- [ ] [Evaluation methods for unsupervised word embeddings](http://www.aclweb.org/anthology/D15-1036)

Additional Readings:
- [ ] [A Latent Variable Model Approach to PMI-based Word Embeddings](http://aclweb.org/anthology/Q16-1028)
- [ ] [Linear Algebraic Structure of Word Senses, with Applications to Polysemy](https://transacl.org/ojs/index.php/tacl/article/viewFile/1346/320)
- [ ] [On the Dimensionality of Word Embedding.](https://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding.pdf)